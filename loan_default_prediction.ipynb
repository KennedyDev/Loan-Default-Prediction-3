{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "\n",
    "# Capstone: Predicting Loan Defaults In Peer-To-Peer Lending\n",
    "\n",
    "## I. Getting Started\n",
    "In this project, we will analyze a dataset containing data on potential borrowers. The goal of this project is to build a model predicting the loan default of potential borrowers. \n",
    "\n",
    "The dataset for this project can be found on [Lending Club](https://www.lendingclub.com/info/download-data.action).\n",
    "\n",
    "Run the code block below to load the wholesale customers dataset, along with a few of the necessary Python libraries required for this project. You will know the dataset loaded successfully if the size of the dataset is reported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loan dataset has 42538 samples with 111 features each.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Load the accepted loan dataset \n",
    "# low_memory and skiprows in read_csv because the file is big\n",
    "try:\n",
    "    loan_data = pd.read_csv(\"LoanStats3a.csv\", low_memory = False, skiprows = 1)\n",
    "    print \"The loan dataset has {} samples with {} features each.\".format(*loan_data.shape)\n",
    "except:\n",
    "    print \"The loan dataset could not be loaded. Is the dataset missing?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction To The Data\n",
    "\n",
    "(explain the process of Lending club loan approval)\n",
    "\n",
    "The dictionary data file is provided with the project in order to refer to it later in our data exploration. This contains information about the various columns and will be useful when we clean up the dataset. The data being used is the data from 2007 to 2011 mostly because when can be almost certain that all the loans have been either repaid or defaulted upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_count = len(loan_data) / 2\n",
    "loan_data = loan_data.dropna(thresh=half_count, axis=1)\n",
    "loan_data = loan_data.drop(['desc', 'url'],axis=1)\n",
    "loan_data.to_csv('loans_2007.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                1077501\n",
       "member_id                      1.2966e+06\n",
       "loan_amnt                            5000\n",
       "funded_amnt                          5000\n",
       "funded_amnt_inv                      4975\n",
       "term                            36 months\n",
       "int_rate                           10.65%\n",
       "installment                        162.87\n",
       "grade                                   B\n",
       "sub_grade                              B2\n",
       "emp_title                             NaN\n",
       "emp_length                      10+ years\n",
       "home_ownership                       RENT\n",
       "annual_inc                          24000\n",
       "verification_status              Verified\n",
       "issue_d                          Dec-2011\n",
       "loan_status                    Fully Paid\n",
       "pymnt_plan                              n\n",
       "purpose                       credit_card\n",
       "title                            Computer\n",
       "zip_code                            860xx\n",
       "addr_state                             AZ\n",
       "dti                                 27.65\n",
       "delinq_2yrs                             0\n",
       "earliest_cr_line                 Jan-1985\n",
       "inq_last_6mths                          1\n",
       "open_acc                                3\n",
       "pub_rec                                 0\n",
       "revol_bal                           13648\n",
       "revol_util                          83.7%\n",
       "total_acc                               9\n",
       "initial_list_status                     f\n",
       "out_prncp                               0\n",
       "out_prncp_inv                           0\n",
       "total_pymnt                       5863.16\n",
       "total_pymnt_inv                   5833.84\n",
       "total_rec_prncp                      5000\n",
       "total_rec_int                      863.16\n",
       "total_rec_late_fee                      0\n",
       "recoveries                              0\n",
       "collection_recovery_fee                 0\n",
       "last_pymnt_d                     Jan-2015\n",
       "last_pymnt_amnt                    171.62\n",
       "last_credit_pull_d               Dec-2016\n",
       "collections_12_mths_ex_med              0\n",
       "policy_code                             1\n",
       "application_type               INDIVIDUAL\n",
       "acc_now_delinq                          0\n",
       "chargeoff_within_12_mths                0\n",
       "delinq_amnt                             0\n",
       "pub_rec_bankruptcies                    0\n",
       "tax_liens                               0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007 = pd.read_csv('loans_2007.csv', low_memory = False)\n",
    "loans_2007.drop_duplicates()\n",
    "\n",
    "loans_2007.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataframe is cumbersome and we had to set the `low_memory` to `False` to avoid a warning message from the notebook. This is due to the numerous columns of the dataset. Let us explore the dataset with the data dictionary this will be useful as we go through the data and try to clean it.\n",
    "\n",
    "We will need to be careful about data from the future, this type of leakage could throw off the useful predictions of our model. A clean example is information about the borrower after the loan was approved, this is not data that we would have at our disposal. \n",
    "\n",
    "We will be splitting the columns in 4 giving us 13 features to analysis and try to make sense of. This part is crucial in order to understand the data and avoid error while fitting our machine learning model later on. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build A Table To Analysis And Visualize\n",
    "We will build a table with 2 csv files. We will use the first entry of the `loans_2007.csv` file to explore the meaning of the 52 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_entry = loans_2007.iloc[0]\n",
    "first_entry.to_csv('first_entry.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = pd.read_csv('LCDataDictionary.csv')\n",
    "\n",
    "description.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "list_first_entry = open('first_entry.csv', 'r')\n",
    "first_csvreader = csv.reader(list_first_entry)\n",
    "first_list = list(first_csvreader)\n",
    "\n",
    "list_data_dictio = open('LCDataDictionary.csv', 'r')\n",
    "second_csvreader = csv.reader(list_data_dictio)\n",
    "second_list = list(second_csvreader)\n",
    "\n",
    "table = []\n",
    "for row in first_list:\n",
    "    table.append(row[0])\n",
    "\n",
    "new_table = []\n",
    "for col in second_list:\n",
    "    if col[0] in table:\n",
    "        new_table.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Set Of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Methodology"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
